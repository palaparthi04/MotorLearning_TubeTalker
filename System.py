from Dataset import Dataset
from PtoAconverter import PtoAconverter
from Talker import Talker
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
import tensorboard
import time
import pandas as pd

# System class creates an object with datasets and networks.
class System():
    def __init__(self, type, parameters):
        super(System, self).__init__()
        # Construct datasets for acoustic, somatosensory and pressure parameters.
        self.constructDatasets(parameters)
        self.parameters = parameters
        # If type of system is training build a network to be trained.
        if type == "training":
            self.buildNetwork(parameters)
            # Specify optimizer and its schedule for use in training of networks.
            learningRate = parameters["FBcontrollers"]["learning-rate"]
            self.schedule = tf.keras.optimizers.schedules.ExponentialDecay(
                float(learningRate),
                decay_steps = 100000,
                decay_rate = 0.98,
                staircase = False
            )
            self.optimizer = tf.keras.optimizers.Adam(learningRate)
            # Mean squared error loss function for training.
            self.loss_fn = tf.keras.losses.MeanSquaredError()
        # Testing uses the same network and loads weights and biases saved at the end of training.
        elif type == "testing":
            self.load_controllers(parameters)
        self.nAcousticBuffer = 128
        self.nPressureBuffer = 1102 # 8820 split into rolling windows.
        self.nParallelBatches = 10000
        # Acoustic prediction buffer saves the values estimated by the converter network used to convert pressures generated by talker to acoustic parameters.
        self.acoustic_predictions_buffer = tf.Variable(np.zeros([self.nParallelBatches, 1, 4, self.nAcousticBuffer], dtype=np.float32), trainable=False)
        pass

    def constructDatasets(self, parameters):
        # Dataset construction for controller design.
        self.control_DataObj = Dataset("FBControl", parameters)
        self.training_dataset = self.control_DataObj.training_data
        self.testing_dataset = self.control_DataObj.testing_data
        # self.testing_dataset_specific = self.control_DataObj.testing_data_specific
        self.pressure_maximum = self.control_DataObj.pressure_maximum
        self.somatosensory_minimums = self.control_DataObj.somatosensory_minimums
        self.somatosensory_maximums = self.control_DataObj.somatosensory_maximums
        pass

    def buildNetwork(self, parameters):
        # Build controllers according to specified structure.
        self.networks = [None]*3
        self.networks[0] = self.create_network(parameters["FBcontrollers"]["networks"])
        self.networks[1] = Talker(parameters["talker"])
        self.networks[2] = PtoAconverter()
        self.networks[2].load(parameters["PtoA"])
        pass

    
    def forwardDynamics(self, inputs):
        # Forward dynamics defines the propagation through the controller-plant network.
        # Split the incomming data into targets and previous predictions.
        somatosensory_targets, somatosensory_predictions, acoustic_targets, acoustic_predictions, muscle_targets = tf.split(inputs, [4, 4, 4, 4, 4], axis=2)
        # allocate new prediction buffers and reset talker for new inputs.
        pressure_predictions = np.zeros([muscle_targets.shape[0], muscle_targets.shape[1], self.nPressureBuffer], dtype=np.float32)
        self.networks[1].resetTalker(self.parameters["talker"])
        acoustic_buffer = np.zeros([acoustic_targets.shape[0], acoustic_targets.shape[1], acoustic_targets.shape[-1], self.nAcousticBuffer], dtype=np.float32)
        # Retransform targets to researcher readable domain.
        acoustic_targets_inv = self.control_DataObj.inverse_transform_to_original_dist(acoustic_targets)
        somatosensory_targets_inv = somatosensory_targets*(self.somatosensory_maximums-self.somatosensory_minimums) + self.somatosensory_minimums
        targets = np.concatenate((muscle_targets, somatosensory_targets_inv, acoustic_targets_inv), axis=-1)
        targets = np.reshape(targets,[targets.shape[0], targets.shape[-1]])
        for epoch in range(8820):  
            with tf.GradientTape() as tape: 
                # Taping allows contruction of backpropagation gradients.         
                # somatosensory_inputs = tf.concat((somatosensory_targets, somatosensory_predictions), axis=-1)
                # acoustic_inputs = tf.concat((acoustic_targets, acoustic_predictions), axis=-1)
                # Somatosensory feedback controller needs somatosensory error as input to make new predictions for muscle inputs to talker.
                somatosensory_inputs = somatosensory_targets-somatosensory_predictions
                # Acoustic feedback controller needs acoustic error as input to make new predictions for muscle inputs to talker.
                acoustic_inputs = acoustic_targets-acoustic_predictions
                # Pass targets and errors to controllers to produce muscle predictions.
                outputs = self.networks[0]([acoustic_targets, somatosensory_inputs, acoustic_inputs], training=True)
                muscle_predictions = outputs[0]
                # muscle predictions are fed to talker to generate both pressure and somatoseneoy predictions.
                somatosensory_predictions = (self.networks[1](np.float32(epoch), muscle_predictions)-self.somatosensory_minimums)/(self.somatosensory_maximums-self.somatosensory_minimums)
                pressure_predictions = self.rollAndAppend(pressure_predictions, self.networks[1].Pox/self.pressure_maximum)
                # pressure predictions are fed to PtoA converter network to generate acoustic predictions.
                acoustic_buffer = self.rollAndAppend_Acoustics(acoustic_buffer, self.networks[2](pressure_predictions))
                acoustic_predictions = tf.reduce_mean(acoustic_buffer, axis=-1)
                # acoustic_predictions = self.networks[2](pressure_predictions)
                # The cost would be the resulting mean squared error between targets and predictions of acoustic, somatosensory and muscle parameters.
                cost = self.loss_fn(tf.concat((acoustic_targets, somatosensory_targets, muscle_targets), axis=-1), tf.concat((acoustic_predictions, somatosensory_predictions, muscle_predictions), axis=-1))
            # Get backpropagation gradients of cost wrt network weights and biases.
            gradients = tape.gradient(cost, self.networks[0].trainable_variables)
            # Update weights and biases for improving estimation.
            self.optimizer.apply_gradients(zip(gradients, self.networks[0].trainable_variables))
            if epoch % 500 == 0:
                # Every 500 iterations print and save results.
                print("iter: {}, cost: {}".format(epoch, cost))
                print("affc: {}, sfbc: {}, afbc: {}".format(outputs[1][0,:,:], outputs[2][0,:,:], outputs[3][0,:,:]))
                print("muscle targets: {}, predictions: {}".format(muscle_targets[0:1,:,:], muscle_predictions[0:1,:,:]))
                print("somatosensory targets: {}, predictions: {}".format(somatosensory_targets[0:1,:,:], somatosensory_predictions[0:1,:,:]))
                print("auditory targets: {}, predictions: {}".format(acoustic_targets[0:1,:,:], acoustic_predictions[0:1,:,:]))
                acoustic_predictions_inv = self.control_DataObj.inverse_transform_to_original_dist(acoustic_predictions)
                somatosensory_predictions_inv = somatosensory_predictions*(self.somatosensory_maximums-self.somatosensory_minimums) + self.somatosensory_minimums
                predictions = np.concatenate((muscle_predictions, somatosensory_predictions_inv, acoustic_predictions_inv), axis=-1)
                predictions = np.reshape(predictions,[predictions.shape[0], predictions.shape[-1]])
                data_df = pd.DataFrame(np.concatenate((targets, predictions), axis=-1))
                with open('controllers_learning_train_results.csv', mode='a') as f:
                    data_df.to_csv(f)
        acoustic_predictions_inv = self.control_DataObj.inverse_transform_to_original_dist(acoustic_predictions)
        somatosensory_predictions_inv = somatosensory_predictions*(self.somatosensory_maximums-self.somatosensory_minimums) + self.somatosensory_minimums
        predictions = np.concatenate((muscle_predictions, somatosensory_predictions_inv, acoustic_predictions_inv), axis=-1)
        predictions = np.reshape(predictions,[predictions.shape[0], predictions.shape[-1]])
        data_df = pd.DataFrame(np.concatenate((targets, predictions), axis=-1))
        with open('controllers_learning_train_results.csv', mode='a') as f:
            data_df.to_csv(f)
        return cost

    # @tf.function
    def train(self, inputs):
        cost = self.forwardDynamics(inputs) 
        return cost
    
    def save_controllers(self, parameters):
        self.networks[0].save_weights(parameters["save-path"] + "/weights")
        pass

    def load_controllers(self, parameters):
        self.test_networks = [None]*3
        self.test_networks[0] = self.create_network(parameters["FBcontrollers"]["networks"])
        self.test_networks[1] = Talker(parameters["talker"])
        self.test_networks[2] = PtoAconverter()
        self.test_networks[2].load(parameters["PtoA"])
        pass
    
    def test(self, parameters, inputs):
        # Similar to forwardDynamics but does not tape to back propagate.
        self.test_networks[0].load_weights(parameters["FBcontrollers"]["save-path"] + "/weights")
        somatosensory_targets, somatosensory_predictions, acoustic_targets, acoustic_predictions, muscle_targets = tf.split(inputs, [4, 4, 4, 4, 4], axis=2)
        pressure_predictions = np.zeros([muscle_targets.shape[0], muscle_targets.shape[1], self.nPressureBuffer], dtype=np.float32)
        self.test_networks[1].resetTalker(self.parameters["talker"])
        acoustic_buffer = tf.Variable(np.zeros([acoustic_targets.shape[0], acoustic_targets.shape[1], acoustic_targets.shape[-1], self.nAcousticBuffer], dtype=np.float32), trainable=False)
        acoustic_targets_inv = self.control_DataObj.inverse_transform_to_original_dist(acoustic_targets)
        somatosensory_targets_inv = somatosensory_targets*(self.somatosensory_maximums-self.somatosensory_minimums) + self.somatosensory_minimums
        targets = np.concatenate((muscle_targets, somatosensory_targets_inv, acoustic_targets_inv), axis=-1)
        targets = np.reshape(targets,[targets.shape[0], targets.shape[-1]])
        targets_norm = np.concatenate((muscle_targets, somatosensory_targets, acoustic_targets), axis=-1)
        targets_norm = np.reshape(targets_norm, [targets_norm.shape[0], targets_norm.shape[-1]])
        Pox_buffer = np.zeros((muscle_targets.shape[0], muscle_targets.shape[1], 8820), dtype=np.float32)
        for epoch in range(8820):
            somatosensory_inputs = somatosensory_targets-somatosensory_predictions
            acoustic_inputs = acoustic_targets-acoustic_predictions
            outputs = self.test_networks[0]([acoustic_targets, somatosensory_inputs, acoustic_inputs], training=True)
            muscle_predictions = outputs[0]
            somatosensory_predictions = (self.test_networks[1](np.float32(epoch), muscle_predictions)-self.somatosensory_minimums)/(self.somatosensory_maximums-self.somatosensory_minimums)
            pressure_predictions = self.rollAndAppend(pressure_predictions, self.test_networks[1].Pox/self.pressure_maximum)
            acoustic_buffer.assign(self.rollAndAppend_Acoustics(acoustic_buffer, self.test_networks[2](pressure_predictions)))
            acoustic_predictions = tf.reduce_mean(acoustic_buffer, axis=-1)
            Pox_buffer[:, :, epoch:epoch+1] = self.test_networks[1].Pox[:, :, 0:1]
            if(epoch%500==0):
                print("Test epoch: {}, affc: {}, sfbc: {}, afbc: {}".format(epoch, outputs[1][0,:,:], outputs[2][0,:,:], outputs[3][0,:,:]))
                print("Error: ", np.median(acoustic_targets[:, :, 3:4]-acoustic_predictions[:, :, 3:4]))
                acoustic_predictions_inv = self.control_DataObj.inverse_transform_to_original_dist(acoustic_predictions)
                somatosensory_predictions_inv = somatosensory_predictions*(self.somatosensory_maximums-self.somatosensory_minimums) + self.somatosensory_minimums
                predictions = np.concatenate((muscle_predictions, somatosensory_predictions_inv, acoustic_predictions_inv, outputs[1], outputs[2], outputs[3]), axis=-1)
                predictions = np.reshape(predictions,[predictions.shape[0], predictions.shape[-1]])
                data_df = pd.DataFrame(np.concatenate((targets, predictions), axis=-1))
                predictions_norm = np.concatenate((muscle_predictions, somatosensory_predictions, acoustic_predictions), axis=-1)
                predictions_norm = np.reshape(predictions_norm, [predictions_norm.shape[0], predictions_norm.shape[-1]])
                data_df_norm = pd.DataFrame(np.concatenate((targets_norm, predictions_norm), axis=-1))
                with open('controllers_learning_test_results.csv', mode='a') as f:
                    data_df.to_csv(f)
                with open('controllers_learning_test_results_norm.csv', mode='a') as f2:
                    data_df_norm.to_csv(f2)
        som_cost = tf.reduce_mean(tf.square(somatosensory_targets - somatosensory_predictions))
        aud_cost = tf.reduce_mean(tf.square(acoustic_targets - acoustic_predictions))
        mus_cost = tf.reduce_mean(tf.square(muscle_targets - muscle_predictions))
        acoustic_predictions_inv = self.control_DataObj.inverse_transform_to_original_dist(acoustic_predictions)
        somatosensory_predictions_inv = somatosensory_predictions*(self.somatosensory_maximums-self.somatosensory_minimums) + self.somatosensory_minimums
        predictions = np.concatenate((muscle_predictions, somatosensory_predictions_inv, acoustic_predictions_inv, outputs[1], outputs[2], outputs[3]), axis=-1)
        predictions = np.reshape(predictions,[predictions.shape[0], predictions.shape[-1]])
        data_df = pd.DataFrame(np.concatenate((targets, predictions), axis=-1))
        predictions_norm = np.concatenate((muscle_predictions, somatosensory_predictions, acoustic_predictions), axis=-1)
        predictions_norm = np.reshape(predictions_norm, [predictions_norm.shape[0], predictions_norm.shape[-1]])
        data_df_norm = pd.DataFrame(np.concatenate((targets_norm, predictions_norm), axis=-1))
        with open('controllers_learning_test_results.csv', mode='a') as f:
            data_df.to_csv(f)
        with open('controllers_learning_test_results_norm.csv', mode='a') as f2:
            data_df_norm.to_csv(f2)
        Pox_df = pd.DataFrame(np.reshape(Pox_buffer, [Pox_buffer.shape[0], Pox_buffer.shape[-1]]))
        with open('Pox_test_data.csv', mode='a') as f3:
            Pox_df.to_csv(f3)
        return som_cost, aud_cost, mus_cost, somatosensory_targets, somatosensory_predictions, acoustic_targets, acoustic_predictions, muscle_targets, muscle_predictions

    def testPerturb(self, parameters, inputs):
        # Induces a perturbation (multiple of target) at 4490 in 8820 samples for estimation.
        # Perturbation induced in parameter k.
        self.test_networks[0].load_weights(parameters["FBcontrollers"]["save-path"] + "/weights")
        somatosensory_targets, somatosensory_predictions, acoustic_targets, acoustic_predictions, muscle_targets = tf.split(inputs, [4, 4, 4, 4, 4], axis=2)
        somatosensory_perturbations = np.zeros(somatosensory_predictions.shape, dtype=np.float32)
        acoustic_perturbations = np.zeros(acoustic_predictions.shape, dtype=np.float32)
        pressure_predictions = np.zeros([muscle_targets.shape[0], muscle_targets.shape[1], self.nPressureBuffer], dtype=np.float32)
        self.test_networks[1].resetTalker(self.parameters["talker"])
        acoustic_buffer = tf.Variable(np.zeros([acoustic_targets.shape[0], acoustic_targets.shape[1], acoustic_targets.shape[-1], self.nAcousticBuffer], dtype=np.float32), trainable=False)
        Pox_buffer = np.zeros((muscle_targets.shape[0], muscle_targets.shape[1], 8820), dtype=np.float32)
        acoustic_targets_inv = self.control_DataObj.inverse_transform_to_original_dist(acoustic_targets)
        somatosensory_targets_inv = somatosensory_targets*(self.somatosensory_maximums-self.somatosensory_minimums) + self.somatosensory_minimums
        targets = np.concatenate((muscle_targets, somatosensory_targets_inv, acoustic_targets_inv), axis=-1)
        targets = np.reshape(targets,[targets.shape[0], targets.shape[-1]])

        targets_norm = np.concatenate((muscle_targets, somatosensory_targets, acoustic_targets), axis=-1)
        targets_norm = np.reshape(targets_norm, [targets_norm.shape[0], targets_norm.shape[-1]])
        k = 3
        file_name = 'controllers_learning_perturbation_test_results_30_aud3_n.csv'
        file_name_norm = 'controllers_learning_perturbation_test_results_30_norm_aud3_n.csv'
        for epoch in range(8820):
            somatosensory_inputs = somatosensory_targets-somatosensory_predictions-somatosensory_perturbations
            acoustic_inputs = acoustic_targets-acoustic_predictions-acoustic_perturbations
            outputs = self.test_networks[0]([acoustic_targets, somatosensory_inputs, acoustic_inputs], training=True)
            muscle_predictions = outputs[0]
            somatosensory_predictions = (self.test_networks[1](np.float32(epoch), muscle_predictions)-self.somatosensory_minimums)/(self.somatosensory_maximums-self.somatosensory_minimums)
            pressure_predictions = self.rollAndAppend(pressure_predictions, self.test_networks[1].Pox/self.pressure_maximum)
            acoustic_buffer.assign(self.rollAndAppend_Acoustics(acoustic_buffer, self.test_networks[2](pressure_predictions)))
            acoustic_predictions = tf.reduce_mean(acoustic_buffer, axis=-1)
            Pox_buffer[:, :, epoch:epoch+1] = self.test_networks[1].Pox[:, :, 0:1]
            if epoch == 4990:
                # somatosensory_perturbations[:, :, k:k+1] = -0.3*somatosensory_targets[:, :, k:k+1]
                acoustic_perturbations[:, :, k:k+1] = -0.3*acoustic_targets[:, :, k:k+1]
                # acoustic_perturbations[:, :, k+1:k+2] = -0.5*acoustic_targets[:, :, k+1:k+2]
            if(epoch%500==0):
                print("Perturb Test epoch: {}, affc: {}, sfbc: {}, afbc: {}".format(epoch, outputs[1][0,:,:], outputs[2][0,:,:], outputs[3][0,:,:]))
                # print(" Acoustic Targets: {}, predictions: {}".format(acoustic_targets[1:3, :, :], acoustic_predictions[1:3, :, :]))
                print("Aud Mean Error: {}, Aud Median Error: {}".format(np.mean(acoustic_targets[:, :, k:k+1]-acoustic_predictions[:, :, k:k+1]), np.median(acoustic_targets[:, :, k:k+1]-acoustic_predictions[:, :, k:k+1])))
                # print("Aud Mean Error: {}, Aud Median Error: {}".format(np.mean(acoustic_targets[:, :, k+1:k+2]-acoustic_predictions[:, :, k+1:k+2]), np.median(acoustic_targets[:, :, k+1:k+2]-acoustic_predictions[:, :, k+1:k+2])))
                # print("Som Mean Error: {}, Som Median Error: {}".format(np.mean(somatosensory_targets[:, :,k:k+1]-somatosensory_predictions[:, :, k:k+1]), np.median(somatosensory_targets[:, :, k:k+1]-somatosensory_predictions[:, :, k:k+1])))
                acoustic_predictions_inv = self.control_DataObj.inverse_transform_to_original_dist(acoustic_predictions)
                somatosensory_predictions_inv = somatosensory_predictions*(self.somatosensory_maximums-self.somatosensory_minimums) + self.somatosensory_minimums
                predictions = np.concatenate((muscle_predictions, somatosensory_predictions_inv, acoustic_predictions_inv, outputs[1], outputs[2], outputs[3]), axis=-1)
                predictions = np.reshape(predictions,[predictions.shape[0], predictions.shape[-1]])
                data_df = pd.DataFrame(np.concatenate((targets, predictions), axis=-1))
                predictions_norm = np.concatenate((muscle_predictions, somatosensory_predictions, acoustic_predictions), axis=-1)
                predictions_norm = np.reshape(predictions_norm, [predictions_norm.shape[0], predictions_norm.shape[-1]])
                data_df_norm = pd.DataFrame(np.concatenate((targets_norm, predictions_norm), axis=-1))
                with open(file_name, mode='a') as f:
                    data_df.to_csv(f)
                with open(file_name_norm, mode='a') as f2:
                    data_df_norm.to_csv(f2)
        # compute somatosensory cost (mean squared error).
        som_cost = tf.reduce_mean(tf.square(somatosensory_targets - somatosensory_predictions))
        # compute auditory cost (mean squared error).
        aud_cost = tf.reduce_mean(tf.square(acoustic_targets - acoustic_predictions))
        # compute muscle cost (mean squared error).
        mus_cost = tf.reduce_mean(tf.square(muscle_targets - muscle_predictions))
        # Denormalize acoustic predictions.
        acoustic_predictions_inv = self.control_DataObj.inverse_transform_to_original_dist(acoustic_predictions)
        # Denormalize somatosensory predictions.
        somatosensory_predictions_inv = somatosensory_predictions*(self.somatosensory_maximums-self.somatosensory_minimums) + self.somatosensory_minimums
        # Save predictions data
        predictions = np.concatenate((muscle_predictions, somatosensory_predictions_inv, acoustic_predictions_inv, outputs[1], outputs[2], outputs[3]), axis=-1)
        predictions = np.reshape(predictions,[predictions.shape[0], predictions.shape[-1]])
        data_df = pd.DataFrame(np.concatenate((targets, predictions), axis=-1))
        predictions_norm = np.concatenate((muscle_predictions, somatosensory_predictions, acoustic_predictions), axis=-1)
        predictions_norm = np.reshape(predictions_norm, [predictions_norm.shape[0], predictions_norm.shape[-1]])
        data_df_norm = pd.DataFrame(np.concatenate((targets_norm, predictions_norm), axis=-1))
        with open(file_name, mode='a') as f:
            data_df.to_csv(f)
        with open(file_name_norm, mode='a') as f2:
            data_df_norm.to_csv(f2)
        Pox_df = pd.DataFrame(np.reshape(Pox_buffer, [Pox_buffer.shape[0], Pox_buffer.shape[-1]]))
        with open('Pox_test_data_aud3_n.csv', mode='a') as f3:
            Pox_df.to_csv(f3)
        return som_cost, aud_cost, mus_cost, somatosensory_targets, somatosensory_predictions, acoustic_targets, acoustic_predictions, muscle_targets, muscle_predictions

    def rollAndAppend(self, A, value):
        # rollAndAppend adds values at the end of buffer, primarly used for pressure buffer.
        temp = tf.transpose(tf.roll(A, shift=-1, axis=-1))
        index = tf.constant([[self.nPressureBuffer-1]])
        return tf.transpose(tf.tensor_scatter_nd_update(temp, index, tf.transpose(value)))

    def rollAndAppend_Acoustics(self, A, value):
        # rollAndAppend_Acoustics adds values at the end of acoustic buffer.
        temp = tf.transpose(tf.roll(A, shift=-1, axis=-1))
        index = tf.constant([[self.nAcousticBuffer-1]])
        return tf.transpose(tf.tensor_scatter_nd_update(temp, index, tf.transpose(tf.reshape(value, (value.shape[0], value.shape[1], value.shape[-1], 1)))))

    def drawInputs(self, type):
        # drawInputs collects and categorizes inputs for different parameters, viz., muscle, somatosensory and acoustic.
        # This processes is done according to type, training draws inputs from training dataset and testing from testing dataset.
        if type=="training":
            muscle_targets, somatosensory_targets, acoustic_targets = tf.split(self.control_DataObj.getFullShuffledDataset(self.training_dataset), [4, 4, 4], axis=-1)
        elif type == "testing":
            muscle_targets, somatosensory_targets, acoustic_targets = tf.split(self.testing_dataset, [4, 4, 4], axis=-1)
        somatosensory_predictions = np.zeros(somatosensory_targets.shape, dtype=np.float32)
        acoustic_predictions = np.zeros(acoustic_targets.shape, dtype=np.float32)
        return tf.concat((somatosensory_targets, somatosensory_predictions, acoustic_targets, acoustic_predictions, muscle_targets), axis=2)

    def TestModules(self, type, parameters):
        if type == "Talker":
            # Generate muscle inputs to the talker.
            controller_outputs = np.reshape(np.asarray([[[0.2, 0.3, 0.2, 0.5]], [[0.2, 0.2, 0.2, 0.5]], [[0.2, 0.3, 0.5, 0.5]]], dtype=np.float32), (3, 1, 4))
            # Test if the same set of muscle inputs generate the same pressure data. (10 trials, 8820 samples each)
            # Tests if reset of the talker parameters is working as it should.
            for _ in range(10):
                i = tf.constant(0.0, dtype=tf.float32, name="sample_iterator")
                def condition(i, inputs):
                    return tf.less(i, 8820.0)
                def body(i, inputs):
                    self.networks[1](i, inputs)
                    return (tf.add(i, 1.0), inputs)
                r = tf.while_loop(condition, body, [i, controller_outputs])
                print(self.networks[1].Pox)
                self.networks[1].resetTalker(parameters["talker"])
        elif type == "PtoA":
            # Tests PtoA converter for 20 x 25ms of pressure buffer data.
            self.networks[2].ReadData(parameters)    
            test_length = self.networks[2].testing_dataset.shape[0]
            testing_inputs, testing_targets = tf.split(self.networks[2].testing_dataset, [1102, 4], axis=-1)
            for i in range(20):
                prediction = self.networks[2](testing_inputs[i:i+1,:,:])
                print("target: {}, prediction: {}".format(testing_targets[i,:,:], prediction))
        pass
        
    def create_network(self, parameters):
        # building controllers tensorflow style.
        # Network contains 3 controllers:
        # a) Auditory feedforward controller (affc)
        # b) Auditory feedback controller (afbc)
        # c) Somatosensory feedback controller (sfbc)
        affc_model = self.create_model(parameters["affc"])
        sfbc_model = self.create_model(parameters["sfbc"])
        afbc_model = self.create_model(parameters["afbc"])
        # nActions: number of inputs
        # Create input layers to each controller.
        inputs1 = layers.Input(shape=(1,parameters["affc"]["nActions"]))
        inputs2 = layers.Input(shape=(1,parameters["sfbc"]["nActions"]))
        inputs3 = layers.Input(shape=(1,parameters["afbc"]["nActions"]))
        # Pass inputs to each controller.
        y1 = affc_model(inputs1)
        y2 = sfbc_model(inputs2)
        y3 = afbc_model(inputs3)
        # Clip the output between 0 and 1 using relu.
        outputs = tf.keras.activations.relu(y1+y2+y3, max_value=1.0)
        return tf.keras.Model(inputs= [inputs1, inputs2, inputs3],outputs=[outputs, y1, y2, y3])

    def create_model(self, parameters):
        # creates network with batch normalization layer.
        # Initialize weights between -3e-3 and 3-e3
        last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)
        # Input layer inside the network.
        inputs = layers.Input(shape=(1, parameters["nActions"]),)
        # Pass the inputs to perceptron layer with precribed activation.
        out = layers.Dense(parameters["structure"][0], activation=parameters["activation"][0])(inputs)
        # Normalization after perceptron layer.
        out = layers.BatchNormalization()(out)
        j = 1
        for i in parameters["structure"][1:]:
            if(parameters["type"]=="perceptron"):
                out = layers.Dense(i, activation=parameters["activation"][j])(out)
                out = layers.BatchNormalization()(out)
                j += 1
            elif(parameters["type"]=="lstm"):
                out = layers.LSTM(i,return_sequences=True)(out)
                out = layers.BatchNormalization()(out)
        # Output layers has number of perceptrons equal to the output variables.      
        outputs = layers.Dense(parameters["nOutputs"], activation=parameters["output-activation"], kernel_initializer=last_init)(out)
        model = tf.keras.Model(inputs, outputs)
        return model